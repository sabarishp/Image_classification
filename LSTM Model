#####
#@Author: Sabarish Palanisamy
#Description: LSTM Model for Bitcoing Price pediction - Daily and Hourly prediction
#Date: 27-May-2018

import numpy as np
import pandas as pd
import keras
import datetime
from math import sqrt
from numpy import concatenate
from keras.models import Sequential  
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.layers.recurrent import LSTM,SimpleRNN
from keras.layers.core import Dense, Activation, Dropout
import time
import seaborn as sns
import plotly.offline as py
import plotly.graph_objs as go
import requests
from matplotlib import pyplot
from keras.callbacks import EarlyStopping
from sklearn.model_selection import GridSearchCV

#Function to convert all the features as per the model requirement
#Shifts the y up by 1 and removes the last record of features
def windowing(scaled_data,n_in=1,n_out=1, dropnan=True): 
    n_vars = 1 if type(scaled_data) is list else scaled_data.shape[1]
    df = pd.DataFrame(scaled_data)
    cols, names = list(), list()
    # This is to create input sequence as t-2, t-1 based on n
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
    # This is to create a future sequence as t, t+1, t+2 based on n
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
    # Create all the t variables in a single frame
    agg = pd.concat(cols, axis=1)
    agg.columns = names
    # drop rows with NaN values
    if dropnan:
        agg.dropna(inplace=True)
    return agg

def mean_absolute_percentage_error(y_act, y_pred): ##Mean absolute ercentage error calculation. The result gives the accuracy
    y_act, y_pred = np.array(y_act), np.array(y_pred)
    return 100-np.mean(np.abs((y_act - y_pred) / y_act)) * 100

def train_test_split(values): #Train and Test Data split 80/20
    n_train_hours = int(len(values) * 0.8)
    train = values[:n_train_hours, :]
    test = values[n_train_hours:, :]
    # split into input and outputs
    train_X, train_y = train[:, :-1], train[:, -1]
    test_X, test_y = test[:, :-1], test[:, -1]
    # reshape input to be 3D [samples, timesteps, features]
    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))
    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))
    return train_X,train_y,test_X,test_y

def model_LSTM_train(units, x_train, y_train,x_test, y_test, epochs, batch_size): #LSTM model building and fitting
    start_time = time.time()
    model = Sequential() #As per time series data, the model is a sequential model
    model.add(LSTM(units,input_shape=(x_train.shape[1],x_train.shape[2]),kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal'))
    model.add(Dense(1)) #One putput layer
    model.compile(optimizer='adam',loss='mae')
    multi_model=model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, validation_data=(x_test,y_test),shuffle=False)#,
                         #callbacks = [EarlyStopping(monitor='val_loss', min_delta=5e-5, patience=20, verbose=1)])
    print("computation time=--- %s seconds ---" % (time.time() - start_time))
    return model,multi_model

def invert(y, x): #Inverse the y value - both pedicted y and actual y
    inv_y = concatenate((y,x[:, 1:]), axis=1)
    inv_y = scaler.inverse_transform(inv_y)
    inv_y = inv_y[:,0]
    return  inv_y

def predict(x_test, y_test, model, model_type): #Prediction on the y , includes mse calculation
    yhat= model.predict(x_test)
    scoreMSE = sqrt(mean_squared_error(y_test, yhat)) # added sqrt of mse
    x_test = x_test.reshape((x_test.shape[0], x_test.shape[2])) #Reshape to 2D from 3D
    yhat = invert(yhat, x_test) #Call the invert function  for y predicted
    y_test = y_test.reshape((len(y_test), 1)) #reshape Y to 2D from 3D
    y_test = invert(y_test, x_test) #Call the invert function again for y actual
    scoreMSE_dollar = sqrt(mean_squared_error(y_test, yhat)) # added sqrt of mse
    print(scoreMSE)
    print(scoreMSE_dollar)
    mape = mean_absolute_percentage_error(y_test, yhat)
    return x_test, y_test, yhat, scoreMSE, scoreMSE_dollar, mape

#This function is to predict the last record that was not used for train /test. This gives the future price
def Predict_NewPrice(scaled, modelLSTM): 
    #predict on the last row
    pred_data = scaled[len(scaled)-1:len(scaled),:] #Separating the final record for prediction
    pred_data = pd.DataFrame(pred_data)
    pred_data = pred_data.values
    pred_data = pred_data.reshape((pred_data.shape[0], 1, pred_data.shape[1]))
    yhat_pred = modelLSTM.predict(pred_data)
    pred_data = pred_data.reshape((pred_data.shape[0], pred_data.shape[2]))
    yhat_pred = invert(yhat_pred, pred_data)
    return yhat_pred

#Overall function for Daily data - includes date column formatting, indexing, taking required features, scaling and calling all other funtions
#Ths function returns the forecast date, price and accuracy of the model
def Main_Daily(data):
    #'''parse parameter'''
    #libraries()
    #Read dataset from file. Dataset already seperated into two files for ease
    #data = pd.read_csv("/data_daily.csv", dayfirst=True)
    
    #Calculating the Future Date based on the last date in the dataset
    LastDate = data['Date'].iloc[data.shape[0]-1]
    date_1 = datetime.datetime.strptime(LastDate, "%Y-%m-%d")
    new_date = date_1 + datetime.timedelta(days=1)
    new_date = new_date.strftime('%Y-%m-%d')

    #Modify the Date format in the input dataframe
    #for i in range (0,len(data['Date'])):
    #    dateold = datetime.datetime.strptime(data['Date'].iloc[i],'%d-%m-%y')
    #    data['Date'].iloc[i] = dateold.strftime('%m-%d-%Y')
    data.set_index('Date',inplace=True) #indexing the data using date
    
    #required feature values
    values = data[['btc_market_price'] + ['dowjones_close'] + ['btc_trade_volume'] + ['btc_hash_rate'] + ['senti_joined']].values
   
    #scaling the data using minmax scaler
    global scaler
    scaler = MinMaxScaler(feature_range = (0,1))
    scaled = scaler.fit_transform(values)
    
    #Reframing the data as per the requirement of the model
    #values = feature_prepare(scaled).astype('float32')
    reframed = windowing(scaled,1,1)
    reframed.drop(reframed.columns[values.shape[1]+1:],axis=1, inplace=True)
    values = reframed.values
    values = values.astype('float32')
    
    #Train test split 80/20
    x_train, y_train, x_test, y_test = train_test_split(values)
        
    #General variables
    units = 100
    epochs = 500
    batch_size =50
    #Train models
    modelLSTM,multi_model = model_LSTM_train(units, x_train, y_train, x_test, y_test, epochs, batch_size)
    
    ##loss plotting - viusalise the change in loss in both train and test
    pyplot.plot(multi_model.history['loss'], label='multi_train')
    pyplot.plot(multi_model.history['val_loss'], label='multi_test')
    pyplot.xlabel("Number of Iterations/epochs")
    pyplot.ylabel("Loss")
    pyplot.legend()
    pyplot.show()
    ####
    
    #Pedicting the Train and test data and calculating all the prediction, rmse, accuracy
    x_train_LSTM, y_train_LSTM, yhat_train_LSTM, RMSE_train_LSTM, RMSE_train_dollar_LSTM, Mape_train_LSTM = predict(x_train, y_train, modelLSTM, 'LSTM')   
    x_test_LSTM, y_test_LSTM, yhat_test_LSTM, RMSE_test_LSTM, RMSE_test_dollar_LSTM, Mape_test_LSTM = predict(x_test, y_test, modelLSTM, 'LSTM')
    new_pred_LSTM = Predict_NewPrice(scaled, modelLSTM)
    print(RMSE_train_LSTM)
    result = ([new_date,Mape_test_LSTM, new_pred_LSTM[0]])
   
    #For first Run - Historical pedictions
    #################################
    #'''
    #Create the Date columns along with last row for pedicted price (First Column of output dataframe)
    df_lastrow = pd.DataFrame([new_date])
    df_col1 = pd.DataFrame(data.index.values)
    df_col1 = df_col1.append(df_lastrow, ignore_index = True)
   
    #merge these 3 as a dataframe along with data to make the second column
    df_col2 = pd.DataFrame(['No Prediction'])
    df_col2 = df_col2.append(pd.DataFrame(yhat_train_LSTM), ignore_index = True)
    df_col2 = df_col2.append(pd.DataFrame(yhat_test_LSTM), ignore_index = True)
    df_col2 = df_col2.append(pd.DataFrame(new_pred_LSTM), ignore_index= True)
    
    df_result = pd.merge(df_col1, df_col2, left_index=True, right_index=True)
    df_result.to_csv('/Predictions_Daily.csv')
    #'''
    return result

#Ths function returns the forecast date, price and accuracy of the model
def Main_Hourly(data):
    #'''parse parameter'''
    #libraries()
    #Read dataset from file. Dataset already seperated into two files for ease
    #data = pd.read_csv("/data_daily.csv", dayfirst=True)
    
    #Calculating the Future Date based on the last date in the dataset
    LastDate = data['Date'].iloc[data.shape[0]-1]
    date_1 = datetime.datetime.strptime(LastDate, "%Y-%m-%d %H:%M:%S")
    new_date = date_1 + datetime.timedelta(hours=1)
    new_date = new_date.strftime('%d-%m-%y %H:%M:%S')
    
    data.set_index('Date',inplace=True)
    
       
    #Modify the Date format in the input dataframe
    #for i in range (0,len(data['Date'])):
    #    dateold = datetime.datetime.strptime(data['Date'].iloc[i],'%d-%m-%y')
    #    data['Date'].iloc[i] = dateold.strftime('%m-%d-%Y')
    
    #required feature values
    values = data[['btc_market_price'] + ['dowjones_close'] + ['btc_volume'] + ['btc_antpoolhashrate'] + ['btc_numtransactions'] + ['senti_joined']].values
   
    #scaling the data using minmax scaler
    global scaler
    scaler = MinMaxScaler(feature_range = (0,1))
    scaled = scaler.fit_transform(values)
    
    #Reframing the data as per the requirement of the model
    #values = feature_prepare(scaled).astype('float32')
    reframed = windowing(scaled,1,1)
    reframed.drop(reframed.columns[values.shape[1]+1:],axis=1, inplace=True)
    values = reframed.values
    values = values.astype('float32')
    
    x_train, y_train, x_test, y_test = train_test_split(values)
        
    #General variables
    units = 100
    epochs = 150
    batch_size = 40
    #Train models
    modelLSTM,multi_model = model_LSTM_train(units, x_train, y_train, x_test, y_test, epochs, batch_size)
    
    ##loss plotting - viusalise the change in loss in both train and test
    pyplot.plot(multi_model.history['loss'], label='Train loss')
    pyplot.plot(multi_model.history['val_loss'], label='Test loss')
    pyplot.xlabel("Number of Iterations/epochs")
    pyplot.ylabel("Loss")
    pyplot.legend()
    pyplot.show()
    ####
    
    x_train_LSTM, y_train_LSTM, yhat_train_LSTM, RMSE_train_LSTM, RMSE_train_dollar_LSTM, Mape_train_LSTM = predict(x_train, y_train, modelLSTM, 'LSTM')   
    x_test_LSTM, y_test_LSTM, yhat_test_LSTM, RMSE_test_LSTM, RMSE_test_dollar_LSTM, Mape_test_LSTM = predict(x_test, y_test, modelLSTM, 'LSTM')
    new_pred_LSTM = Predict_NewPrice(scaled, modelLSTM)
   
    result = ([new_date, Mape_test_LSTM, new_pred_LSTM[0]])
    
    #'''
    #For first Run - Historical pedictions
    #Create the Date columns along with last row for pedicted price (First Column of output dataframe)
    df_lastrow = pd.DataFrame([new_date])
    df_col1 = pd.DataFrame(data.index.values)
    df_col1 = df_col1.append(df_lastrow, ignore_index = True)
   
    #merge these 3 as a dataframe along with data to make the second column
    df_col2 = pd.DataFrame(['No Prediction'])
    df_col2 = df_col2.append(pd.DataFrame(yhat_train_LSTM), ignore_index = True)
    df_col2 = df_col2.append(pd.DataFrame(yhat_test_LSTM), ignore_index = True)
    df_col2 = df_col2.append(pd.DataFrame(new_pred_LSTM), ignore_index= True)
    
    df_result = pd.merge(df_col1, df_col2, left_index=True, right_index=True)
    df_result.to_csv('/Predictions_Hourly.csv')
    
    #'''
    return result

#pass data file and call the functions inside the same file - Not required when calling from another file
data_1 = pd.read_csv("/data_daily_2018-06-03.csv", dayfirst=True)
result1 = Main_Daily(data_1)
print(result1)
data_2 = pd.read_csv("/data_hourly_2018-06-03-15.csv")
result2 = Main_Hourly(data_2)
print(result2)
